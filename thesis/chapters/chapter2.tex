\chapter{Monte Carlo Methods Applied to the Ising Model}

A short review of the Monte Carlo (MC) methods used to solve the Ising Model in the current paradigm is presented. There will be a focus on the famous Metropolis Method and the Wang-Landau sampling. 

\section{Metropolis}

The classic Metropolis method belongs to the Markov chain Monte Carlo (MCMC) class of algorithms. These algorithms exploit the fact that if we construct a Markov chain that has a specific equilibrium distribution one can obtain samples recording the states generated by the Markov chain. 

In a brief fashion, a Markov chain is a stochastic model that describes a sequence of possible events, in this case microstates,in which the probability of transiting to another state depends on the current state. This way the probability of the next state, $S_j$, given the current state, $S_i$, can be written as 
\begin{equation}
	P(S_j, t) = \sum_i W(S_i \rightarrow S_j) P(S_i, t),
\end{equation}
where $W(S_i \rightarrow S_j) \equiv W_{ij}$ is the transition probability to move from the state $i$ to $j$. We require that 
\begin{equation}
	W_{ij}  \geq 0 \quad \quad \quad \quad \quad \sum_j W_{ij}=1.
\end{equation}
The master equation considers the change of the probability of the next state with time, $t$,
\begin{equation}
	\frac{dP(S_j, t)}{dt} = \sum_i \left[ W_{ij}P(S_i, t) - W_{ji} P(S_j,t)  \right].
\end{equation}
In the equilibrium regime, the master equation has o equal $0$, and we get the detailed balance condition for the equilibrium probability $P_{eq}(S_j)$,
\begin{equation}
	W_{ji}P_{eq}(S_j) = W_{ij}P_{eq}(S_i).
\end{equation}

The object of Metropolis Sampling is to generate canonical configurations with an equilibrium probability
\begin{equation} \label{eq:met_prob_eq}
	P_{eq}(E_i) = \frac{\exp(-\beta E_i)}{Z}.
\end{equation}
Here $Z$ is the partition function, however this is usually not know before hand. When considering a Markovian process we generate each new configuration from the preceding one avoiding this problem. As a result the difference of energy between the two states is needed, $\Delta E = E_i - E_j$ and the transition probability of given as

\begin{equation}
	W_{ij} = \twopartdef { \tau_0^{-1} \exp(-\beta \Delta E) } {\Delta E \geq 0} {\tau_0^{-1}} {\Delta E < 0}
\end{equation}
where $\tau_0^{-1}$ is the time required to attempt a spin-flip.  We often set this time unit to one.

This way the Metropolis Method applied to the Ising Model, with a fixed external magnetic field and a fixed temperature, goes as follows:

\begin{table}[h]
\begin{tabular}{ll}
(1) & Choose an initial state;                                                                                                                                                          \\
(2) & Choose a spin $i$ and perform a spin-flip;                                                                                                                                        \\
(3) & Calculate the energy change from that spin-flip, $\Delta E$;                                                                                                                      \\
(4) & Accept the flip with a probability $\min \left( 1, \exp(-\beta \Delta E) \right)$; 
\\
(5) & Measure any thermodynamic quantity needed;                                                                                                                                        \\
(6) & Go back to (2) and repeat until desired.                                                                                                                                         
\end{tabular}
\end{table}
Note that we accept the spin flip if a given uniformly random number $r, r \in [0,1]$, is less or equal to the acceptance criteria. Typically in Monte Carlo simulations we define the MC time as the amount of trial flips equal to the number of spins in our lattice, N.

\subsection{Success and Limitations}

The Metropolis Sampling proposed by Metropolis et al., can be successfully applied to an array of models, ranging from widely studied quantum ensembles and gases simulations to state-of-the-art protein and peptide simulations and to machine learning and neural networks. The following paragraphs will be directed to magnetic systems, like the Ising model, but they can be extrapolated to others physical systems. 

When getting thermodynamic variables we have to let the simulation reach the equilibrium stage, where the probability distribution takes the form of equation \ref{eq:met_prob_eq}. Then we take a measurement each MC time, resulting in $M$ total values for that variable. At the end the average if that variable, $A$, is taken $\langle A \rangle = \frac{1}{M} \sum_i A_i$. 
For large systems the time taken to reach equilibrium stage is often very long thus making the simulation time consuming. 

This is worsen by the fact that to study how some thermodynamic variable $A$ changes over a wide range of temperatures or applied fields intensities, we need to run multiple Metropolis simulations for each temperature and field intensity values, making this process very time-consuming.

Lastly there is another shortcoming known as critical slowing down. In short, for computations where the temperature is near the critical temperature, $T_C$, the sampling slows down, meaning that it is more time-consuming for the computations to reach the equilibrium stage, thus slowing down the overall simulation.

\section{Wang-Landau}

Since its introduction the Metropolis Sampling was the go-to method to study phase transitions and critical phenomena in condensed matter physics and statistical mechanics. In the final decades of the 20th century scientists were committed to develop new methods that could overcome the shortcomings of the Metropolis Sampling. Various methods were proposed such as the cluster flip algorithms, where Swendsen and Wang where pioneers, and the multicanonical ensemble method. The first solved the critical slowing down present in the Metropolis and the second could sample rough energy landscapes with ease. 












\subsection{Algorithm}

\subsection{Variations}

\subsection{Success and Limitations}
